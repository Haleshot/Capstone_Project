{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlabonne/llm-course/blob/main/Fine_tune_LLMs_with_Axolotl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL-BPZyZ0gtV"
      },
      "source": [
        "# Fine-tune LLMs with Axolotl\n",
        "\n",
        "> üó£Ô∏è [Large Language Model Course](https://github.com/mlabonne/llm-course)\n",
        "\n",
        "‚ù§Ô∏è Created by [@maximelabonne](https://twitter.com/maximelabonne), based on [Giorgio](https://github.com/g-i-o-r-g-i-o)'s notebook and Axolotl's [example](https://github.com/OpenAccess-AI-Collective/axolotl/blob/main/examples/colab-notebooks/colab-axolotl-example.ipynb).\n",
        "\n",
        "\n",
        "Heavily adapted and modified per custom usecase from above resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import yaml\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "import wandb\n",
        "from huggingface_hub import HfApi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'Capstone_Project/'\n",
            "/teamspace/studios/this_studio/Capstone_Project\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
            "  bkms = self.shell.db.get('bookmarks', {})\n"
          ]
        }
      ],
      "source": [
        "%cd Capstone_Project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/teamspace/studios/this_studio/Capstone_Project'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): Traceback (most recent call last):\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/bin/huggingface-cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 52, in main\n",
            "    service.run()\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
            "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 115, in login\n",
            "    interpreter_login(new_session=new_session, write_permission=write_permission)\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 191, in interpreter_login\n",
            "    token = getpass(\"Enter your token (input will not be visible): \")\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/getpass.py\", line 77, in unix_getpass\n",
            "    passwd = _raw_input(prompt, stream, input=input)\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/getpass.py\", line 146, in _raw_input\n",
            "    line = input.readline()\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/codecs.py\", line 319, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "with open('config.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AxolotlLightningModule(pl.LightningModule):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            config['base_model'],\n",
        "            load_in_8bit=config['load_in_8bit'],\n",
        "            load_in_4bit=config['load_in_4bit'],\n",
        "            torch_dtype=torch.float16 if config['fp16'] else torch.float32,\n",
        "            use_flash_attention_2=False  # Add this line\n",
        "        )\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(config['base_model'])\n",
        "        \n",
        "        # Save hyperparameters for wandb logging\n",
        "        self.save_hyperparameters(config)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self.model(**batch)\n",
        "        loss = outputs.loss\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.AdamW(self.model.parameters(), lr=self.config['learning_rate'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def prepare_dataset(config):\n",
        "#     dataset = load_dataset(config['datasets'][0]['path'])\n",
        "#     print(f\"Available splits in the dataset: {dataset.keys()}\")\n",
        "\n",
        "#     if 'train' in dataset:\n",
        "#         train_dataset = dataset['train_sft']\n",
        "#     else:\n",
        "#         # If there's no 'train' split, use the first available split\n",
        "#         first_split = list(dataset.keys())[0]\n",
        "#         print(f\"No 'train' split found. Using '{first_split}' as the training dataset.\")\n",
        "#         train_dataset = dataset[first_split]\n",
        "\n",
        "#     if config['val_set_size'] > 0:\n",
        "#         split = train_dataset.train_test_split(test_size=config['val_set_size'])\n",
        "#         return split['train'], split['test']\n",
        "#     else:\n",
        "#         return train_dataset, None\n",
        "\n",
        "def prepare_dataset(config):\n",
        "    dataset = load_dataset(config['datasets'][0]['path'])\n",
        "    print(f\"Available splits in the dataset: {dataset.keys()}\")\n",
        "\n",
        "    if 'train_sft' in dataset and 'test_sft' in dataset:\n",
        "        train_dataset = dataset['train_sft']\n",
        "        val_dataset = dataset['test_sft']\n",
        "        print(f\"Using 'train_sft' for training and 'test_sft' for validation.\")\n",
        "    else:\n",
        "        raise ValueError(\"Expected 'train_sft' and 'test_sft' splits not found in the dataset.\")\n",
        "\n",
        "    return train_dataset, val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upload_to_huggingface(model, tokenizer, config):\n",
        "    model.push_to_hub(config['new_model'], use_auth_token=True)\n",
        "    tokenizer.push_to_hub(config['new_model'], use_auth_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    # Initialize wandb\n",
        "    wandb.init(project=config['wandb_project'], entity=config['wandb_entity'], name=config['wandb_name'])\n",
        "\n",
        "    # Prepare dataset\n",
        "    train_dataset, val_dataset = prepare_dataset(config)\n",
        "\n",
        "    # Initialize model\n",
        "    model = AxolotlLightningModule(config)\n",
        "\n",
        "    # Initialize WandbLogger\n",
        "    wandb_logger = WandbLogger(project=config['wandb_project'], log_model=config['wandb_log_model'])\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=config['num_epochs'],\n",
        "        logger=wandb_logger,\n",
        "        gradient_clip_val=1.0,\n",
        "        accumulate_grad_batches=config['gradient_accumulation_steps'],\n",
        "        val_check_interval=config['evals_per_epoch'] if config['evals_per_epoch'] else 1.0,\n",
        "        precision=16 if config['fp16'] else 32,\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.fit(model, train_dataloaders=train_dataset, val_dataloaders=val_dataset)\n",
        "\n",
        "    # Upload the model to HuggingFace\n",
        "    upload_to_huggingface(model.model, model.tokenizer, config)\n",
        "\n",
        "    # [Optional] Finish the wandb run\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:cf4a11r9) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4437cff6874842069d4b72d93dc412ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vibrant-cosmos-6</strong> at: <a href='https://wandb.ai/haleshot-SVKM%27s%20Narsee%20Monjee%20Institute%20of%20Management%20St/Capstone_Project/runs/cf4a11r9' target=\"_blank\">https://wandb.ai/haleshot-SVKM%27s%20Narsee%20Monjee%20Institute%20of%20Management%20St/Capstone_Project/runs/cf4a11r9</a><br/> View project at: <a href='https://wandb.ai/haleshot-SVKM%27s%20Narsee%20Monjee%20Institute%20of%20Management%20St/Capstone_Project' target=\"_blank\">https://wandb.ai/haleshot-SVKM%27s%20Narsee%20Monjee%20Institute%20of%20Management%20St/Capstone_Project</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240929_110655-cf4a11r9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.18.2 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:cf4a11r9). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed12f8fd1bf2460783b1143f6e02d13d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112203633333845, max=1.0‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/teamspace/studios/this_studio/Capstone_Project/wandb/run-20240929_111202-sqtqtz3f</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/haleshot-SVKM%27s%20Narsee%20Monjee%20Institute%20of%20Management%20St/Capstone_Project/runs/sqtqtz3f' target=\"_blank\">silver-glade-7</a></strong> to <a href='https://wandb.ai/haleshot-SVKM%27s%20Narsee%20Monjee%20Institute%20of%20Management%20St/Capstone_Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/haleshot-SVKM%27s%20Narsee%20Monjee%20Institute%20of%20Management%20St/Capstone_Project' target=\"_blank\">https://wandb.ai/haleshot-SVKM%27s%20Narsee%20Monjee%20Institute%20of%20Management%20St/Capstone_Project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/haleshot-SVKM%27s%20Narsee%20Monjee%20Institute%20of%20Management%20St/Capstone_Project/runs/sqtqtz3f' target=\"_blank\">https://wandb.ai/haleshot-SVKM%27s%20Narsee%20Monjee%20Institute%20of%20Management%20St/Capstone_Project/runs/sqtqtz3f</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available splits in the dataset: dict_keys(['train_sft', 'test_sft'])\n",
            "Using 'train_sft' for training and 'test_sft' for validation.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/import_utils.py:1745\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:32\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttentionMaskConverter\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_flash_attention_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _flash_attention_forward\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     BaseModelOutputWithPast,\n\u001b[1;32m     35\u001b[0m     CausalLMOutputWithPast,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     TokenClassifierOutput,\n\u001b[1;32m     39\u001b[0m )\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flash_attn_2_available():\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert_padding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m index_first_axis, pad_input, unpad_input  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flash_attn_func, flash_attn_varlen_func\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flash_attn/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.6.3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflash_attn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_attn_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     flash_attn_func,\n\u001b[1;32m      5\u001b[0m     flash_attn_kvpacked_func,\n\u001b[1;32m      6\u001b[0m     flash_attn_qkvpacked_func,\n\u001b[1;32m      7\u001b[0m     flash_attn_varlen_func,\n\u001b[1;32m      8\u001b[0m     flash_attn_varlen_kvpacked_func,\n\u001b[1;32m      9\u001b[0m     flash_attn_varlen_qkvpacked_func,\n\u001b[1;32m     10\u001b[0m     flash_attn_with_kvcache,\n\u001b[1;32m     11\u001b[0m )\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flash_attn/flash_attn_interface.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# We need to import the CUDA kernels after importing torch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mflash_attn_2_cuda\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mflash_attn_cuda\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n",
            "\u001b[0;31mImportError\u001b[0m: /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[29], line 9\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m prepare_dataset(config)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAxolotlLightningModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize WandbLogger\u001b[39;00m\n\u001b[1;32m     12\u001b[0m wandb_logger \u001b[38;5;241m=\u001b[39m WandbLogger(project\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwandb_project\u001b[39m\u001b[38;5;124m'\u001b[39m], log_model\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwandb_log_model\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "Cell \u001b[0;32mIn[26], line 5\u001b[0m, in \u001b[0;36mAxolotlLightningModule.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbase_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload_in_8bit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload_in_4bit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfp16\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_flash_attention_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Add this line\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_model\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Save hyperparameters for wandb logging\u001b[39;00m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:556\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    553\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    554\u001b[0m     )\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 556\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    558\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    559\u001b[0m     )\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m )\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:383\u001b[0m, in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[0;32m--> 383\u001b[0m     supported_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:728\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping:\n\u001b[1;32m    727\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[model_type]\n\u001b[0;32m--> 728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[1;32m    731\u001b[0m model_types \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m key\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:742\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:686\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[0;32m--> 686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[1;32m    688\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/import_utils.py:1735\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1735\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1736\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/import_utils.py:1747\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.llama.modeling_llama because of the following error (look up to see its traceback):\n/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BI6B0Bfe0hxr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'axolotl' already exists and is not an empty directory.\n",
            "\n",
            "\n",
            "\u001b[38;5;57m\u001b[1m‚ö°Ô∏è Tip\u001b[0m\tCheck organization access: \u001b[4mhttps://github.com/settings/connections/applications/c7457225b242a94d60c6\u001b[0m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/teamspace/studios/this_studio/axolotl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Cannot install None and axolotl because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!git clone -q https://github.com/OpenAccess-AI-Collective/axolotl\n",
        "%cd axolotl\n",
        "!pip install -qqq packaging huggingface_hub --progress-bar off\n",
        "!pip install -qqq -e '.[flash-attn,deepspeed]' --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement axolotl (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for axolotl\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install axolotl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.17.9)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (4.23.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (6.0.0)\n",
            "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (2.13.0)\n",
            "Requirement already satisfied: setproctitle in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (72.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhaleshot\u001b[0m (\u001b[33mhaleshot-SVKM's Narsee Monjee Institute of Management St\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "70zJf1hi0huQ"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "new_model = \"Haleshot/Mathmate-7B-DELLA-ORPO\"\n",
        "yaml_string = \"\"\"\n",
        "base_model: Haleshot/Mathmate-7B-DELLA\n",
        "model_type: LlamaForCausalLM\n",
        "tokenizer_type: LlamaTokenizer\n",
        "is_llama_derived_model: true\n",
        "\n",
        "load_in_8bit: true\n",
        "load_in_4bit: false\n",
        "strict: false\n",
        "\n",
        "datasets:\n",
        "  - path: HuggingFaceTB/everyday-conversations-llama3.1-2k\n",
        "    # type: alpaca\n",
        "dataset_prepared_path:\n",
        "val_set_size: 0.05\n",
        "output_dir: ./qlora-out\n",
        "\n",
        "adapter: qlora\n",
        "lora_model_dir:\n",
        "\n",
        "sequence_len: 1096\n",
        "sample_packing: true\n",
        "pad_to_sequence_len: true\n",
        "\n",
        "lora_r: 32\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "lora_target_modules:\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "\n",
        "wandb_project:\n",
        "wandb_entity:\n",
        "wandb_watch:\n",
        "wandb_name:\n",
        "wandb_log_model:\n",
        "\n",
        "# mlflow_experiment_name: colab-example\n",
        "\n",
        "gradient_accumulation_steps: 1\n",
        "micro_batch_size: 1\n",
        "num_epochs: 4\n",
        "max_steps: 20\n",
        "optimizer: paged_adamw_32bit\n",
        "lr_scheduler: cosine\n",
        "learning_rate: 0.0002\n",
        "\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: false\n",
        "fp16: true\n",
        "tf32: false\n",
        "\n",
        "gradient_checkpointing: true\n",
        "early_stopping_patience:\n",
        "resume_from_checkpoint:\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention:\n",
        "flash_attention: false\n",
        "\n",
        "warmup_steps: 10\n",
        "evals_per_epoch:\n",
        "saves_per_epoch:\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.0\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Convert the YAML string to a Python dictionary\n",
        "yaml_dict = yaml.safe_load(yaml_string)\n",
        "\n",
        "# Specify your file path\n",
        "yaml_file = 'config.yaml'\n",
        "\n",
        "# Write the YAML file\n",
        "with open(yaml_file, 'w') as file:\n",
        "    yaml.dump(yaml_dict, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffcc0IB9Sr-z",
        "outputId": "f64291b0-0867-440b-b7b9-683fa66e3a08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `0`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1745, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py\", line 28, in <module>\n",
            "    from ...image_processing_utils import ImageProcessingMixin\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/image_processing_utils.py\", line 21, in <module>\n",
            "    from .image_transforms import center_crop, normalize, rescale\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/image_transforms.py\", line 22, in <module>\n",
            "    from .image_utils import (\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/image_utils.py\", line 58, in <module>\n",
            "    from torchvision.transforms import InterpolationMode\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/_meta_registrations.py\", line 164, in <module>\n",
            "    def meta_nms(dets, scores, iou_threshold):\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/library.py\", line 467, in inner\n",
            "    handle = entry.abstract_impl.register(func_to_register, source)\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_library/abstract_impl.py\", line 30, in register\n",
            "    if torch._C._dispatch_has_kernel_for_dispatch_key(self.qualname, \"Meta\"):\n",
            "RuntimeError: operator torchvision::nms does not exist\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"/teamspace/studios/this_studio/axolotl/src/axolotl/cli/__init__.py\", line 29, in <module>\n",
            "    from axolotl.common.cli import TrainerCliArgs, load_model_and_tokenizer\n",
            "  File \"/teamspace/studios/this_studio/axolotl/src/axolotl/common/cli.py\", line 12, in <module>\n",
            "    from axolotl.utils.models import load_model, load_tokenizer\n",
            "  File \"/teamspace/studios/this_studio/axolotl/src/axolotl/utils/models.py\", line 18, in <module>\n",
            "    from peft import (\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/__init__.py\", line 22, in <module>\n",
            "    from .auto import (\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/auto.py\", line 32, in <module>\n",
            "    from .mapping import MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/mapping.py\", line 22, in <module>\n",
            "    from peft.tuners.xlora.model import XLoraModel\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/__init__.py\", line 21, in <module>\n",
            "    from .lora import LoraConfig, LoraModel, LoftQConfig, LoraRuntimeConfig\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/lora/__init__.py\", line 20, in <module>\n",
            "    from .model import LoraModel\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/lora/model.py\", line 50, in <module>\n",
            "    from .awq import dispatch_awq\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/peft/tuners/lora/awq.py\", line 26, in <module>\n",
            "    from awq.modules.linear import WQLinear_GEMM\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/awq/__init__.py\", line 2, in <module>\n",
            "    from awq.models.auto import AutoAWQForCausalLM\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/awq/models/__init__.py\", line 1, in <module>\n",
            "    from .mpt import MptAWQForCausalLM\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/awq/models/mpt.py\", line 1, in <module>\n",
            "    from .base import BaseAWQForCausalLM\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/awq/models/base.py\", line 35, in <module>\n",
            "    from transformers import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1736, in __getattr__\n",
            "    value = getattr(module, name)\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1735, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1747, in _get_module\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Failed to import transformers.models.auto.processing_auto because of the following error (look up to see its traceback):\n",
            "operator torchvision::nms does not exist\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 1174, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 769, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/home/zeus/miniconda3/envs/cloudspace/bin/python', '-m', 'axolotl.cli.train', 'config.yaml']' returned non-zero exit status 1.\n"
          ]
        }
      ],
      "source": [
        "!accelerate launch -m axolotl.cli.train config.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GENnc9Z8v-P",
        "outputId": "762e6290-9877-485c-c084-5370c3b3d7f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/bin/python3: Error while finding module specification for 'axolotl.cli.merge_lora' (ModuleNotFoundError: No module named 'axolotl.cli')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m axolotl.cli.merge_lora config.yaml --lora_model_dir=\"./qlora-out\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "76eab4e675b34a5486f28d16183658b6",
            "af7f38e810a64e5f98dd3f33672b8d57",
            "0e196628e7e64879bcc7184f67404127",
            "2ee0d001c05a4b89ab7a3cbea71c5960",
            "8a59f96ead334ba8b6848321fbde0811",
            "3db6a3ae89ec483783f97d77aef5e5a7",
            "f589d24de591428cb878405d1eb6034d",
            "e4520b22ca934c1fbe399131c021d0e8",
            "cb663cc62fc94108855d9b5509b573d8",
            "9926acc37862427d9fdd1ef37474d0c9",
            "215f84842ac5451a8f868e0dc3090a71",
            "0878f651a6b64ef495ebd5a2a9084b63",
            "eec99342bca04c1697ec43bc099c22c9",
            "cb7cc89f3edf4c6c8e38043ef0d697ba",
            "7a9497ed06004a82b2893e0f5ab03736",
            "f50ea1d3c5874926a6db2af3d9d795ab",
            "7851c929f5f64e31856d3793b963130e",
            "49f8123c3c5e43ababed7e09e97cb7d2",
            "c4dfec3f687241d6a69cf30252ada077",
            "a1c9ecf2bc124658a08f585b1bf309e6",
            "101d0b228b1943ff9c9d69fd6f4847ee",
            "b03c7fa74c774a39946636803e086218",
            "90726b0049c344c19fb5c9ef1dcf0628",
            "bebef38ee9e24586a7f894ffaf1ae43e",
            "9d90c5ea423e4586bc3bb303bcaa4b03",
            "d417d5bf00294e3f9cb7e78b5d83ee03",
            "68eac408135d4d048de89fa674b701da",
            "34c11d3b1a3441bf8533f7a6f057d0cf",
            "6270a81b7f5749d7a656c1edaaa63118",
            "e1de7a96086c4351bba99bbd4d905802",
            "6d28893d0a054d6aa2726ee94ee0d880",
            "91c9822b8ef14074bd360bb5d2998267",
            "8673edee8ab5430588daba8d422999eb"
          ]
        },
        "id": "NsvZw3B7-gfm",
        "outputId": "68c10dec-ee7a-4c0d-dd8d-c6631b53f4b3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76eab4e675b34a5486f28d16183658b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0878f651a6b64ef495ebd5a2a9084b63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90726b0049c344c19fb5c9ef1dcf0628",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/mlabonne/TinyAlpaca/commit/0428c0eb7a6c18dfb7ce7a4cd86ecf4e397048f9', commit_message='Upload folder using huggingface_hub', commit_description='', oid='0428c0eb7a6c18dfb7ce7a4cd86ecf4e397048f9', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from huggingface_hub import HfApi\n",
        "from google.colab import userdata\n",
        "\n",
        "new_model = \"Haleshot/Mathmate-7B-DELLA-ORPO-everyday\"\n",
        "\n",
        "# HF_TOKEN defined in the secrets tab in Google Colab\n",
        "api = HfApi()\n",
        "\n",
        "# Upload merge folder\n",
        "api.create_repo(\n",
        "    repo_id=new_model,\n",
        "    repo_type=\"model\",\n",
        "    exist_ok=True,\n",
        ")\n",
        "api.upload_folder(\n",
        "    repo_id=new_model,\n",
        "    folder_path=\"qlora-out/merged\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0878f651a6b64ef495ebd5a2a9084b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eec99342bca04c1697ec43bc099c22c9",
              "IPY_MODEL_cb7cc89f3edf4c6c8e38043ef0d697ba",
              "IPY_MODEL_7a9497ed06004a82b2893e0f5ab03736"
            ],
            "layout": "IPY_MODEL_f50ea1d3c5874926a6db2af3d9d795ab"
          }
        },
        "0e196628e7e64879bcc7184f67404127": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4520b22ca934c1fbe399131c021d0e8",
            "max": 2200164718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb663cc62fc94108855d9b5509b573d8",
            "value": 2200164718
          }
        },
        "101d0b228b1943ff9c9d69fd6f4847ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "215f84842ac5451a8f868e0dc3090a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ee0d001c05a4b89ab7a3cbea71c5960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9926acc37862427d9fdd1ef37474d0c9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_215f84842ac5451a8f868e0dc3090a71",
            "value": " 2.20G/2.20G [01:14&lt;00:00, 34.5MB/s]"
          }
        },
        "34c11d3b1a3441bf8533f7a6f057d0cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db6a3ae89ec483783f97d77aef5e5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f8123c3c5e43ababed7e09e97cb7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6270a81b7f5749d7a656c1edaaa63118": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68eac408135d4d048de89fa674b701da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d28893d0a054d6aa2726ee94ee0d880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76eab4e675b34a5486f28d16183658b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af7f38e810a64e5f98dd3f33672b8d57",
              "IPY_MODEL_0e196628e7e64879bcc7184f67404127",
              "IPY_MODEL_2ee0d001c05a4b89ab7a3cbea71c5960"
            ],
            "layout": "IPY_MODEL_8a59f96ead334ba8b6848321fbde0811"
          }
        },
        "7851c929f5f64e31856d3793b963130e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a9497ed06004a82b2893e0f5ab03736": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_101d0b228b1943ff9c9d69fd6f4847ee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b03c7fa74c774a39946636803e086218",
            "value": " 2/2 [01:14&lt;00:00, 74.58s/it]"
          }
        },
        "8673edee8ab5430588daba8d422999eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a59f96ead334ba8b6848321fbde0811": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90726b0049c344c19fb5c9ef1dcf0628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bebef38ee9e24586a7f894ffaf1ae43e",
              "IPY_MODEL_9d90c5ea423e4586bc3bb303bcaa4b03",
              "IPY_MODEL_d417d5bf00294e3f9cb7e78b5d83ee03"
            ],
            "layout": "IPY_MODEL_68eac408135d4d048de89fa674b701da"
          }
        },
        "91c9822b8ef14074bd360bb5d2998267": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9926acc37862427d9fdd1ef37474d0c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d90c5ea423e4586bc3bb303bcaa4b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1de7a96086c4351bba99bbd4d905802",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d28893d0a054d6aa2726ee94ee0d880",
            "value": 499723
          }
        },
        "a1c9ecf2bc124658a08f585b1bf309e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af7f38e810a64e5f98dd3f33672b8d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db6a3ae89ec483783f97d77aef5e5a7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f589d24de591428cb878405d1eb6034d",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "b03c7fa74c774a39946636803e086218": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bebef38ee9e24586a7f894ffaf1ae43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34c11d3b1a3441bf8533f7a6f057d0cf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6270a81b7f5749d7a656c1edaaa63118",
            "value": "tokenizer.model: 100%"
          }
        },
        "c4dfec3f687241d6a69cf30252ada077": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb663cc62fc94108855d9b5509b573d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb7cc89f3edf4c6c8e38043ef0d697ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4dfec3f687241d6a69cf30252ada077",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1c9ecf2bc124658a08f585b1bf309e6",
            "value": 2
          }
        },
        "d417d5bf00294e3f9cb7e78b5d83ee03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91c9822b8ef14074bd360bb5d2998267",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8673edee8ab5430588daba8d422999eb",
            "value": " 500k/500k [00:00&lt;00:00, 48.1kB/s]"
          }
        },
        "e1de7a96086c4351bba99bbd4d905802": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4520b22ca934c1fbe399131c021d0e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eec99342bca04c1697ec43bc099c22c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7851c929f5f64e31856d3793b963130e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_49f8123c3c5e43ababed7e09e97cb7d2",
            "value": "Upload 2 LFS files: 100%"
          }
        },
        "f50ea1d3c5874926a6db2af3d9d795ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f589d24de591428cb878405d1eb6034d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
